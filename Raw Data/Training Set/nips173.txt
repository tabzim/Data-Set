"Information Maximization in Single Neurons." Advances in neural information processing systems. 1999.
Information from the senses must be compressed into the limited range 
of firing rates generated by spiking nerve cells. Optimal compression 
uses all firing rates equally often, implying that the nerve cell's response 
matches the statistics of naturally occurring stimuli. Since changing 
the voltage-dependent ionic conductances in the cell membrane alters 
the flow of information, an unsupervised, non-Hebbian, developmental 
learning rule is derived to adapt the conductances in Hodgkin-Huxley 
model neurons. By maximizing the rate of information transmission, 
each firing rate within the model neuron's limited dynamic range is used 
equally often. 
An efficient neuronal representation of incoming sensory information should take advan- 
tage of the regularity and scale invariance of stimulus features in the natural world. In 
the case of vision, this regularity is reflected in the typical probabilities of encountering 
particular visual contrasts, spatial orientations, or colors Ill. Given these probabilities, an 
optimized neural code would eliminate any redundancy, while devoting increased repre- 
sentation to commonly encountered features. 
At the level of a single spiking neuron, information about a potentially large range of stimuli 
is compressed into a finite range of firing rates, since the maximum firing rate of a neuron is 
limited. Optimizing the information transmission through a single neuron in the presence 
of uniform, additive noise has an intuitive interpretation: the most efficient representation 
of the input uses every firing rate with equal probability. An analogous principle for non- 
spiking neurons has been tested experimentally by Laughlin [2], who matched the statistics 
