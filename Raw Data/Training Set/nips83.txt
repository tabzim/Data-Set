"Support Vector Method for Novelty Detection." Advances in Neural Information Processing Systems. 2000. 
Suppose you are given some dataset drawn from an underlying probabil- 
ity distribution P and you want to estimate a "simple" subset $ of input 
space such that the probability that a test point drawn from P lies outside 
of $ equals some a priori specified v between 0 and 1. 
We propose a method to approach this problem by trying to estimate a 
function f which is positive on $ and negative on the complement. The 
functional form of f is given by a kernel expansion in terms of a poten- 
tially small subset of the training data; it is regularized by controlling the 
length of the weight vector in an associated feature space. We provide a 
theoretical analysis of the statistical performance of our algorithm. 
The algorithm is a natural extension of the support vector algorithm to 
the case of unlabelled data. 
